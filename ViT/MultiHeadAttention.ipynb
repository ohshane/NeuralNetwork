{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiheadAttention(\n",
       "  (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "attention = nn.MultiheadAttention(3, 1)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4958, -0.8534, -0.4214],\n",
       "        [-0.8438,  0.1714, -0.6490]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3292, -0.0839, -0.0926],\n",
       "         [-0.3436, -0.0839, -0.0979]], grad_fn=<SqueezeBackward1>),\n",
       " tensor([[0.5116, 0.4884],\n",
       "         [0.4686, 0.5314]], grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(x, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('in_proj_weight',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.1405, -0.3945,  0.5471],\n",
       "                      [-0.1265, -0.5828, -0.5495],\n",
       "                      [-0.2209, -0.3847,  0.6708],\n",
       "                      [ 0.1557, -0.6537,  0.5884],\n",
       "                      [-0.3887, -0.2024, -0.5411],\n",
       "                      [-0.1282,  0.2785,  0.5890],\n",
       "                      [ 0.6437, -0.6600,  0.3784],\n",
       "                      [-0.1468,  0.0951, -0.6093],\n",
       "                      [-0.1017, -0.2700, -0.2403]], requires_grad=True)),\n",
       "             ('q_proj_weight', None),\n",
       "             ('k_proj_weight', None),\n",
       "             ('v_proj_weight', None),\n",
       "             ('in_proj_bias',\n",
       "              Parameter containing:\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1757, -0.3041],\n",
       "         [ 0.7916,  0.3635],\n",
       "         [ 0.1551, -0.3148]], grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.2327, -0.6253],\n",
       "         [ 0.5935,  0.6445],\n",
       "         [-0.4224, -0.2264]], grad_fn=<SliceBackward0>),\n",
       " tensor([[ 0.0846, -0.9019],\n",
       "         [ 0.2484,  0.5356],\n",
       "         [ 0.3821,  0.1955]], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (attention._parameters['in_proj_weight'] @ x.T)\n",
    "Q, K, V = z[:3], z[3:6], z[6:]\n",
    "Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2310, -0.0917, -0.0054],\n",
       "        [-0.0430,  0.7041, -0.4166],\n",
       "        [ 0.2330, -0.1108,  0.0058]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q @ K.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
