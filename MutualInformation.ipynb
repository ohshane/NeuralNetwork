{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/abs/1807.06653\n",
    "# Invariant Information Clustering for Unsupervised Image Classification and Segmentation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf x, \\mathbf x' \\in \\mathcal X \\\\\n",
    "\\Phi : \\mathcal X \\to \\mathcal Y\n",
    "$$\n",
    "\n",
    "* For example $\\mathbf x$ and $\\mathbf x'$ could be different images containing the same object ($\\mathbf x'$ as an arbitrary augmented data of $\\mathbf x$).\n",
    "* $\\mathbf x$ and $\\mathbf x'$ are highly correlated, which can be seen as a paired datapoints from a joint probability distribution $P(\\mathbf x, \\mathbf x')$.\n",
    "* The goal is to maximize the mutual information ($I$) while discarding instance-specific details.\n",
    "\n",
    "$$\n",
    "\\max_{\\Phi} I(\\Phi(\\mathbf x), \\Phi(\\mathbf x'))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = torch.randn(8)\n",
    "\n",
    "proba = logit.softmax(0)\n",
    "proba_aug = (logit*.5).softmax(0)\n",
    "\n",
    "print(f\"{proba     = }\")\n",
    "print(f\"{proba_aug = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = proba.reshape(8,1) @ proba_aug.reshape(8,1).T\n",
    "P = (P + P.T)/2\n",
    "\n",
    "eps = 0.01\n",
    "P[P < eps] = eps\n",
    "\n",
    "Pi = P.sum(dim=1).view(8,1).expand(8,8)\n",
    "Pj = P.sum(dim=0).view(1,8).expand(8,8)\n",
    "\n",
    "plt.subplot(1,5,1)\n",
    "plt.title(r\"$P_{cc'}$\")\n",
    "plt.imshow(P)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,5,2)\n",
    "plt.title(r\"$P_{c}$\")\n",
    "plt.imshow(Pi)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,5,3)\n",
    "plt.title(r\"$P_{c'}$\")\n",
    "plt.imshow(Pj)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,5,4)\n",
    "plt.title(r\"$P_{c} P_{c'}$\")\n",
    "plt.imshow(Pi * Pj)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,5,5)\n",
    "plt.title(r\"$I(P)$\")\n",
    "plt.imshow(P * (P/(Pi*Pj)).log())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('MI:', (P * (P/(Pi*Pj)).log()).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual Information, Clearly Explained - StatQuest (https://youtu.be/eJIp_mgVLwE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Joint probability\\\n",
    "Events occuring at the same time\n",
    "\n",
    "- Marginal probability\\\n",
    "Just the probability of one thing occuring\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\hline \\hline \\textbf{ Likes Popcorn } & \\cdots & \\textbf { Loves Troll } \\\\\n",
    "\\hline\n",
    "\\text{ Yes } & \\cdots & \\text{ Yes } \\\\\n",
    "\\text{ Yes } & \\cdots & \\text{ Yes } \\\\\n",
    "\\text{ Yes } & \\cdots & \\text{ Yes } \\\\\n",
    "\\text{ No  } & \\cdots & \\text{ No  } \\\\\n",
    "\\text{ No  } & \\cdots & \\text{ Yes } \\\\\n",
    "\\hline\n",
    "\\end{array} \\\\[20pt]\n",
    "\n",
    "\\begin{align*}\n",
    "&\\text{Table 1.1. Contingency table} \\\\\n",
    "&\\begin{array}{ccc}\n",
    "\\hline \\hline & \\textbf{ Likes Popcorn } & \\textbf{ Dislikes Popcorn } & \\Pr(\\textbf{ Troll }) \\\\\n",
    "\\hline\n",
    "\\textbf{ Loves Troll } & {3}/{5} & {1}/{5} & {4}/{5} \\\\\n",
    "\\textbf{ Hates Troll } & {0}/{5} & {1}/{5} & {1}/{5} \\\\\n",
    "\\hline\n",
    "\\Pr(\\textbf{ Popcorn }) & {3}/{5} & {2}/{5} & \\\\\n",
    "\\end{array}\n",
    "\\end{align*} \\\\[20pt]\n",
    "\n",
    "\\begin{align*}\n",
    "&\\text{Table 1.2. Contingency table when independent} \\\\\n",
    "&\\begin{array}{ccc}\n",
    "\\hline \\hline & \\textbf{ Likes Popcorn } & \\textbf{ Dislikes Popcorn } & \\Pr(\\textbf{ Troll }) \\\\\n",
    "\\hline\n",
    "\\textbf{ Loves Troll } & {12}/{25} & {8}/{25} & {4}/{5} \\\\\n",
    "\\textbf{ Hates Troll } & {3}/{25} & {2}/{25} & {1}/{5} \\\\\n",
    "\\hline\n",
    "\\Pr(\\textbf{ Popcorn }) & {3}/{5} & {2}/{5} & \\\\\n",
    "\\end{array}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "fun fact : The _marginal probabilities_ are placed in the margins of the table. (Joint probabilities are placed inside of the table)\n",
    "\n",
    "Mutual information ($I$) can be expressed as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "I(X,Y) &= \\sum\\limits_{x \\in X} \\sum\\limits_{y \\in Y} p(x,y) \\log \\left[ \\dfrac{p(x,y)}{p(x)p(y)} \\right] \\\\\n",
    "&= \\dfrac{3}{5} \\log \\dfrac{{3}/{5}}{{12}/{25}} + \\cdots + \\dfrac{1}{5} \\log \\dfrac{{1}/{5}}{{2}/{25}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0087357"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I(X,Y) = \\sum\\limits_{x \\in X} \\sum\\limits_{y \\in Y} p(x,y) \\log \\left[ \\dfrac{p(x,y)}{p(x)p(y)} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I(\\Phi(\\mathbf x), \\Phi(\\mathbf x')) = \\sum\\limits_{i} \\sum\\limits_{j} p(\\Phi(x_i), \\Phi(x'_j)) \\log \\left[ \\dfrac{p(\\Phi(x_i), \\Phi(x'_j))}{p(\\Phi(x_i))p(\\Phi(x'_j))} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I(\\Phi(\\mathbf x), \\Psi(\\mathbf x)) = \\sum\\limits_{i} \\sum\\limits_{j} p(\\Phi(x_i), \\Psi(x_j)) \\log \\left[ \\dfrac{p(\\Phi(x_i), \\Psi(x_j))}{p(\\Phi(x_i))p(\\Psi(x_j))} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def softmax_mutual_information(x, y):\n",
    "    # Apply softmax to the vectors\n",
    "    x_softmax = F.softmax(x, dim=-1)\n",
    "    y_softmax = F.softmax(y, dim=-1)\n",
    "    \n",
    "    # Calculate the probabilities\n",
    "    p_x = x_softmax.mean(dim=0)\n",
    "    p_y = y_softmax.mean(dim=0)\n",
    "    p_xy = torch.matmul(x_softmax.unsqueeze(-1), y_softmax.unsqueeze(-2)).mean(dim=0).flatten()\n",
    "    \n",
    "    # Compute mutual information\n",
    "    mutual_info = (p_xy * (torch.log(p_xy) - torch.log(p_x.unsqueeze(-1)) - torch.log(p_y.unsqueeze(-1)))).sum()\n",
    "    \n",
    "    return mutual_info.item()\n",
    "\n",
    "# Example usage:\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([0.5, 1.5, 2.5])\n",
    "mi = softmax_mutual_information(x, y)\n",
    "print(\"Mutual Information:\", mi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
